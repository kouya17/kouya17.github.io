<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Posts | kouya17.com</title>
<meta name=keywords content>
<meta name=description content="Posts - kouya17.com">
<meta name=author content>
<link rel=canonical href=https://kouya17.com/posts/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.a97cdb2d52ff3547f5b45210b2262edb8517a9ced99357596eea2f6dda9f6aad.css integrity="sha256-qXzbLVL/NUf1tFIQsiYu24UXqc7Zk1dZbuovbdqfaq0=" rel="preload stylesheet" as=style>
<link rel=icon href=https://kouya17.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://kouya17.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://kouya17.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://kouya17.com/apple-touch-icon.png>
<link rel=mask-icon href=https://kouya17.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.91.2">
<link rel=alternate type=application/rss+xml href=https://kouya17.com/posts/index.xml>
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-92576104-3','auto'),ga('send','pageview'))</script><meta property="og:title" content="Posts">
<meta property="og:description" content>
<meta property="og:type" content="website">
<meta property="og:url" content="https://kouya17.com/posts/"><meta property="og:site_name" content="kouya17.com">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Posts">
<meta name=twitter:description content>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://kouya17.com/posts/"}]}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8855472249928298" crossorigin=anonymous></script>
</head>
<body class=list id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://kouya17.com accesskey=h title="kouya17.com (Alt + H)">kouya17.com</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://kouya17.com/archives/ title=Archives>
<span>Archives</span>
</a>
</li>
<li>
<a href=https://kouya17.com/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
<li>
<a href=https://kouya17.com/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<header class=page-header><div class=breadcrumbs><a href=https://kouya17.com>Home</a></div>
<h1>Posts</h1>
</header>
<article class=post-entry>
<header class=entry-header>
<h2>PostgreSQL+Echo+cron+Next.jsでWebスクレイピングシステムを構成する
</h2>
</header>
<section class=entry-content>
<p>今回作ったシステムのデモ 以下が今回作ったシステムの動作時の動画になる。
上の動画のように、情報を取得したい物件一覧が表示されるURL及びジョブを識別するためのタグを登録する。登録されたジョブはキューに保存される。上の動画では分からないが、ジョブは毎分1件ずつ実行される。
ジョブが実行され、システムに保存された情報は以下のような一覧画面から確認できる。
システムの全体構成図 本システムの全体構成は以下のようになっている。
以下4つの要素に分けてそれぞれDockerコンテナ化している。
Next.jsコンテナ Echoコンテナ cronコンテナ PostgreSQLコンテナ Webスクレイピングの流れ 本システムにおけるWebスクレイピングの流れは以下のとおりである。
ジョブを登録する データの取得先URLを登録する。このURLは、不動産情報サイトの検索結果ページを指定する。今は数種類のサイトに対応している。また、タグを指定することでそのジョブに名前のようなものをつけることができる。
過去に実行したものと同じ条件であれば再実行ボタンからも実行できる。
ジョブが実行される 登録されたジョブは1個ずつ順番に実行される。実行が開始されると、ジョブ一覧画面で対象ジョブのStatusがrunningに変化する。
ジョブは登録されたURLによって検索表示される不動産情報を1個ずつ、ある程度の時間間隔を空けながら取得する。すべての不動産情報が取得出来たら地価情報サイトから対象物件付近の地価(1平米あたり)を取得する。この情報もAreaPriceとして物件情報に含める。この地価情報と土地面積及び物件価格から建物の想定価格を計算し、EstimatedBuildingPriceとして物件情報に含める。なお、地価は頻繁に変わる情報ではないのでデータベースに保存しておき再利用する。
実行が終了するとジョブ一覧画面で対象ジョブのStatusがcompletedに変化する。
物件情報一覧画面から取得した物件情報を確認する 物件一覧ページにおいて、最新ジョブで取得された行は赤枠で表示される。検索欄でJobIdを範囲指定することもできるので、複数ジョブを実行した場合はそれらのジョブによって取得されたものを絞り込むこともできる。
なお、すでに登録されている物件URLと同じURLを持つ物件が取得された場合は、価格を比較する。価格が更新されていた場合は物件情報とJobIdを上書きする。
物件一覧において、行をクリックすると対象物件ページに遷移する。対象物件をクリックした回数も保持しており、1回以上クリックした物件は黄色で塗りつぶされて表示される。そのため、過去自分が詳細をチェックした物件かどうか一目で見分けがつくようになっている。
ソースコード </p>
</section>
<footer class=entry-footer><span title="2023-01-26 20:02:00 +0900 +0900">January 26, 2023</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to PostgreSQL+Echo+cron+Next.jsでWebスクレイピングシステムを構成する" href=https://kouya17.com/posts/real_estate_app/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>Maker Faire Tokyo 2022に出展した
</h2>
</header>
<section class=entry-content>
<p>Maker Faire Tokyo 2022に出展してきた。Maker Faire Tokyoは初参加になる。
出展内容 「固定砲台型射的ゲームHODAI」と「中に入っているものを記録・検索できる棚SShelf」を展示した。それぞれの展示について、以下詳細ページを作成している。
固定砲台型射的ゲームHODAI https://home.lchika.club/posts/hodai-system SShelf https://home.lchika.club/posts/sshelf 展示時のレイアウトは以下のようにした。展示スペースの大部分を「固定砲台型射的ゲームHODAI」が占めている。的ユニットと砲台ユニットについては展示スペース後方に設置した折りたたみテーブルの上に乗せている。
設営完了しました。#MFTokyo2022 pic.twitter.com/ZErMsK1kV3
— 青木晃也 (@aoki_kouya) September 3, 2022 「固定砲台型射的ゲームHODAI」について、スコアデータを取っているのだが、2日間で177個のスコアが作成された。ゲーム中の時間を説明の時間に充てた方もいるので、スコアデータの数=遊んでくれた回数にはならないが、たくさんの回数、ゲームを遊んでいただけた。
ついでに本日の固定砲台型射的ゲームHODAIのスコアのヒストグラムも掲載。本日パーフェクト(12点)を記録した方はいませんでした。 pic.twitter.com/3lubvcdyEH
— 青木晃也 (@aoki_kouya) September 4, 2022 今回の展示に関して、振り返りを以下にまとめる。
今回の展示に関して良かったこと 致命的な故障は発生しなかった。 初日に通信部のソフト不具合でシステムの再起動が数回必要になった。 初日終盤にサーボ(SG90)が1個怪しい挙動になったが、初日終了後に予備と交換し解消した。 2日目終盤に砲台とLCDの接続が若干怪しくなったが、再起動で解消できた。 総じて長時間のメンテナンスが必要になる事態は起きなかった。 説明動画を作成することで説明の時間を一部省けた。 モニターで説明動画を流すことで、結構な人が目を通してくれた。 今回の展示に関して良くなかったこと 展示の詳細説明サイトを作成したが、QRコードを読みこんでくれる方はほぼいなかった。 来場者の方に「QRコードを読みこんでもらう」というのは大分ハードルが高いらしかった。 SShelfの方は体験するために「スマホを特定のSSIDにつなぐ」必要があるのだが、こちらもかなりハードルが高かったと思う。 「体験できるものかどうか」が一目で分かるような展示になっていなかった。 一応「遊べる」というのが今回の展示の特徴の1つではあるのだが、その特徴が一目では分かりずらい展示になっていたと思う。 2日目は"遊べます"というポップを置いたことで、若干来場者の方の反応が良くなった(気がする)。 ルール説明が大変だった。 出来るだけシステムの自動化はしているのだが、細かいルール説明は人力になるので、そこの労力が必要になった。 荷物が多かった。 ワンオペなのに無茶した。 けど一応やり切れたので多少の自信にはなった。 他の方の展示のレポート 事前に気になっていた展示を絞り込んで、2日目午前の間に見学した。展示レポートを以下にまとめる。...</p>
</section>
<footer class=entry-footer><span title="2022-09-10 13:03:00 +0900 +0900">September 10, 2022</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to Maker Faire Tokyo 2022に出展した" href=https://kouya17.com/posts/mft2022/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>[C#]YouTubeLiveチャットに特定の文字列が書き込まれたことを検知する
</h2>
</header>
<section class=entry-content>
<p>試作ソフト動作時の様子 APIキー及び対象配信のURLを入力し、チャットを取得する。取得したチャットに対し、特定文字列が含まれているものを抽出して表示する。
上記GIF右側にあるソフトのコードは以下に置いている。
実装内容の詳細 YouTubeLiveチャットの取得 YouTubeLiveチャットはYouTube Data APIを利用して取得する。YouTube Data APIは、YouTubeが公開している、YouTube上の情報を参照及び変更できるAPIである。コードサンプルページを見ると、以下の言語向けのクライアントライブラリがあることを確認できる。
Go Java JavaScript .NET PHP Python Ruby 今回は.NET用のGoogleAPIクライアントライブラリを使う。
APIキーの準備 YouTube Data APIを利用するために、APIキーを作成する必要がある。APIキーの作成方法はここでは詳しく記載しない。以下のサイト等を参考にしてほしい。
プロジェクトへのライブラリーの追加 プロジェクトにGoogle.Apis.YouTube.v3をインストールする。以下手順の説明はVisual Studio 2022の利用を想定している。
Visual Studio 2022のタブから プロジェクト > NuGetパッケージの管理 を選択する。 Google.Apis.YouTube.v3を検索し、最新バージョンをインストールする。 プログラムの実装 チャットを取得するコードを実装する。チャットを取得するまでの流れは以下のような形にしている。
配信URLからVideo IDを取得する。 Video IDからData APIを使って対象配信のChat IDを取得する。 Chat IDからLive Streaming APIを使ってチャットのデータを取得する。 配信URLからVideo IDを取得する Video IDは配信URLのクエリパラメータ中のvパラメータに相当する。例えば、配信URLがhttps://www.youtube.com/watch?v=fLM31tHrD5MであればfLM31tHrD5MがVideo IDである。
Video ID抽出のための処理はSystem.Web.HttpUtility.ParseQueryString()を利用した。以下に実装のサンプルを記載する。なお、下記サンプルはvパラメータがない場合を想定していない。
var uri = new Uri(stringUrl); // stringUrlには配信URLが入る var query = System....</p>
</section>
<footer class=entry-footer><span title="2022-06-12 18:44:00 +0900 +0900">June 12, 2022</span>&nbsp;·&nbsp;2 min</footer>
<a class=entry-link aria-label="post link to [C#]YouTubeLiveチャットに特定の文字列が書き込まれたことを検知する" href=https://kouya17.com/posts/youtube-chat-hooks1/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>Raspberry Pi Zero W を使ってタイムラプス生成デバイスを作成する
</h2>
</header>
<section class=entry-content>
<p>デモ 本デバイスは以下の動画のように操作できる。
操作時の動画は以下のような感じです。 pic.twitter.com/7l2ocbjlh1
— 青木晃也 (@aoki_kouya) March 20, 2022 本デバイスを使うと、以下のサイトにあるような動画を生成できる。
動画の出力条件のうち、主な項目は以下の通り。
再生速度: 30倍速 fps: 30 bps: 3Mbps HLS形式 音声なし 料理の動画を掲載しているのは、特に他にコンスタントに撮影できる対象が考えつかなかったため。これらの動画の撮影のために、3Dプリンターでプリントした部品を使ってラズパイとカメラを固定し、台所上部に吊り下げている。
Raspberry Pi Zeroを使って、思い付きでタイムラプスカメラを作りました。 pic.twitter.com/w1fCBfPVzm
— 青木晃也 (@aoki_kouya) March 5, 2022 確認済み動作条件 ボード Raspberry Pi Zero W OS Raspberry Pi OS(Legacy) 2022-01-28 現時点(2022/03/21)で推奨OSとなっているRaspberry Pi OSはbullseye版だが、buster版(Legacy)の方を使う。これは、ffmpeg(今回利用するマルチメディア処理ソフト)まわりの環境がbullseye版とbuster版で異なっているため。bullseye版を利用する場合、ハードウェアエンコードを有効にするために、ffmpegをビルドする必要が出てくる。
必要な部品 Raspberry Pi Zero W (スイッチサイエンス) microSDカード (Amazon) Raspberry Pi カメラモジュール (スイッチサイエンス) Raspberry Pi Zero用カメラケーブル (スイッチサイエンス) ELECROW 3....</p>
</section>
<footer class=entry-footer><span title="2022-03-21 13:03:00 +0900 +0900">March 21, 2022</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to Raspberry Pi Zero W を使ってタイムラプス生成デバイスを作成する" href=https://kouya17.com/posts/timelapse-maker/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>ReactでYouTubeのプレーヤーを制御する
</h2>
</header>
<section class=entry-content>
<p>react-youtubeというReactコンポーネントを利用したサンプルサイトを作成したので、紹介する。
作成したサンプルサイト ページを開くと、特定のYouTube動画が読みこまれる。YouTubeプレーヤーを操作する毎に操作情報(+操作時の再生位置)が記録される。記録された操作は、YouTubeプレーヤー下にテキストで表示される。操作情報は、「download」ボタンを押すことでファイルとして出力できる。
上記サンプルサイトでは、現状以下の操作のみ記録する。
再生準備完了(ready) 再生開始(play) 一時停止(pause) 再生終了(end) 視聴者毎の動画視聴状況を確認したいケースを考える 今回のサンプルサイトは、「視聴者ごとに、動画の視聴状況詳細を確認したいケース」を想定して作成した。視聴者は操作情報をファイルとして出力し、管理者へ提出する。管理者は提出されたファイルから、視聴状況を確認するという想定である。サンプルでは操作情報をファイルで出力しているが、これを「ユーザー情報を付与してサーバー上に保存」とかすれば、ファイルをやり取りするという手続きは不要になる。
今回想定したケースのように、YouTubeから情報を取得したい場合の手段としては、YouTube Data APIを活用するという方法がある。ただ、YouTube Data APIには、「特定のユーザーの、各視聴動画に対する操作情報」という細かい情報までは用意されていない。取得できても「特定のユーザーの視聴履歴」までである。
少し調べたところ、YouTubeのIFrame Player APIを使うと、YouTubeプレーヤーに対する操作を取得出来るようだったので、今回はそちらを利用した。
YouTubeのIFrame Player APIを利用する IFrame Player APIを利用することで、再生中の動画に関する情報を取得できる。情報の取得はJavaScript関数を使って行う。また、特定のプレーヤーイベントに対して、イベントリスナーを設定できる。今回のサンプルサイトを例にすると、再生準備完了(onReady)、再生開始(onPlay)、一時停止(onPause)、再生終了(onEnd)に対してイベントリスナーを設定している。
今回のサンプルサイトはNext.jsを使って作成したため、ReactコンポーネントとしてIFrame Player APIを利用できるreact-youtubeを利用した。
サンプルサイトの作成とデプロイ サンプルサイトの実装内容としては、react-youtubeのサンプルに、プレーヤーイベント発生時のイベントリスナーを設定し、操作情報を画面に出力及びファイルとしてダウンロード出来るようにしたくらいである。
ソースコードは以下に公開している。
サンプルサイトはGitHub Pagesを使って稼働させている。GitHub Pagesへのデプロイは、GitHub Actionsを利用して、mainブランチ更新時に自動で行われるようにしている。ここら辺は、以下のサイトを参考にさせていただいた。
</p>
</section>
<footer class=entry-footer><span title="2022-01-15 13:15:00 +0900 +0900">January 15, 2022</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to ReactでYouTubeのプレーヤーを制御する" href=https://kouya17.com/posts/react-youtube/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>機械学習を使ってApexのプレイ動画から武器使用率を算出する
</h2>
</header>
<section class=entry-content>
<p>最終的な目標はプレイスタイルの解析 近年、動画投稿・配信サービスの普及により、ゲーム実況というものがエンタメの1カテゴリとして確立してきていると思う。感染症流行の影響が大きいと思うが、2021年1月～3月の主要ゲーム配信サイト(Twitch、YouTube Gaming、Facebook Gaming)の合計視聴時間が前年同期比で80%増加したというデータもある。1ゲームのジャンルとしてはアクション・RPG・シミュレーションなどあらゆるものが実況の対象になるが、今回はFPSのゲーム実況にスポットを当てる。
FPSの分野では、オンライン対戦システムおよび、いわゆるランクシステムが整備されているものが多くなっている。ランクシステムは、プレイヤーの習熟度のようなものを可視化する。こうしたランクに関する情報は、視聴者にとって、プレイヤーのことをパッと理解するために非常に役立っていると思う。
現状、ランク情報やダメージ数、キルデス比等はゲームシステムから参照できるようになっていることが多いと思う。ただ、個人的にはより細かい、プレイヤーのプレイスタイルのようなものを可視化できる情報があると、プレイヤーについて理解を深めるためのよい材料になると思った。
最終的にはゲームシステムから直接確認出来るデータだけでなく、ゲームプレイ動画の解析結果から、プレイヤーのプレイスタイルをうまく可視化したい。今回は、Apexを題材にし、プレイヤーのプレイスタイルを示す1つの指標として、武器使用率をゲームプレイ動画から解析できないか試す。まあ、こういった情報はわざわざ動画を解析しなくても、ゲームシステム側で実装してもらえれば、より正確で容易にデータが取れるとは思う。
全体の作業の流れ 今回の全体の作業の流れは以下のようになっている。
各作業の内容について説明していく。ただし、ゲームプレイ動画のキャプチャ作業については特に説明することがないので、何も説明しない。
武器名表示領域の切り取り データセットを整備するために、ゲーム画面のうち、武器名を表示している領域のみを切り取った画像を作成する必要がある。今回は、動画に対して一定時間ごとのフレームを画像化→特定領域を切り取り→特定の場所に画像ファイルとして保存、という流れでデータセット用の画像を作成した。
一連の画像切り取り作業実施のために、ツールを作成した。GUI部分はPySimpleGUIを利用している。
主に以下を設定できる。
切り取り対象とする動画の保存場所 武器1欄(*1)の画像を保存する場所 武器2欄(*1)の画像を保存する場所 画像を切り抜く領域(*2)(全体サイズに対する割合で指定) (*2)で設定した領域からどれだけずらした画像を何個保存するか 画像切り取り対象とするフレームの時間間隔 (*1)Apexでは、武器を同時に2つ持つことができる。今回は武器1欄と武器2欄を別々のデータセットとして扱う。理由はそちらの方がより精度が上がりそうと思ったためである。
このツールを使えば、ボタンを1回ポチーすることで、後は待っていれば所定の場所に武器名表示領域の画像が保存される。
画像に対して正解ラベルを付ける データセットの正解ラベル付けについて、どのような形式で保存するのが一般的かを私は知らないのだが、今回は各正解ラベル(武器名)ごとに保存フォルダを分けることにした。
以下のように、全武器+“武器なし”(_None)について画像をフォルダ分けした。
この作業にも専用ツールを作成した。
データセットが置かれている場所を指定して、startボタンを押すと、所定の個数づつ未分類の画像が表示される。表示された画像について、正解となる武器名のボタンをポチポチしていき、画像をフォルダ分けする。
ただ、今回データセットの元にしたキャプチャ動画は武器を決まった順番で使うようにしていた。そのため、切り抜かれた画像が最初から決まった武器順で並んでおり、結局このツールはあまり使わなかった。
学習・モデルの保存 データセットの準備が出来たので、ようやく学習をする。学習部分はコードベースで説明する。
まず、データセットの読み込みを行う。かなりコードが汚い。武器名のリストは、以下のコードに含まれていない関数を使ってファイルから読みこんでいる。
Kerasを用いてモデルを生成する関数を作成する。
Optunaを使ってハイパーパラメータを調整しつつ、成績の良いモデルを保存する。(といってもマシンが貧弱で学習に時間がかかるので、5回しか試行を回していない。)
上記のコードを実行したところ、とりあえず今回はテストデータの正解率が99.89%のモデルが出来た。テストデータの推論結果をMatplotlibを使って画像とともに確認してみる。
いい感じに推論できてそうだ。誤答をしたデータについても確認してみる。
今回は2つのデータの推論が間違っていたようだ。上は正答がFlatlineなのに対し、Devotionと推論してしまっており、下は正答がNoneなのに対し、R-301と推論してしまっている。
作成したモデルによるプレイ動画の解析 モデルが出来たので、動画を解析する。解析用のソフトを作成した。
学習用に使ったデータとは別のキャプチャ動画を使って解析したところ、以下のような結果になった。
解析結果を見たところ、大体は合っていると思うが、誤検出されている武器名が末尾に並んでいる。解析結果は正確なものではないため、データの扱いは少し考えないといけない。
最初は自作モデルを作らなくても行けると思っていた 今回、武器使用率算出のために"機械学習のモデルを作成・利用する"という手段を選択した。
この手段を取る前は、TesseractとPyOCRを利用して文字列を認識する方法をとっていた。ただ、認識精度が厳しかったので、利用を断念した。機械学習の勉強にもなると思い、代わりに自作モデルの作成という方法をとった。
今回の識別対象は決まり切った文字列なので、機械学習を使わなくても、より正確な認識方法があるかもしれない。というか、私はApexにあまり詳しくないので、そもそもゲームシステム内で武器使用率を確認できる方法があるかもしれない。
参考にした書籍・動画 機械学習については主にネット上の情報と、以下の書籍の内容を流し読みした程度の理解度である。
ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装 オライリージャパン (2016/9/24) Amazon 楽天市場 また、上記書籍を数年前に読んだときは誤差逆伝播法がいまいち理解できなかった。しかし、Twitterのタイムラインで流れてきた以下の動画が非常に参考になり、とりあえず分かった気にはなれた。出来るだけ条件を簡易にして、高校数学の範囲で説明されている。
まとめ 機械学習を利用してApexのプレイ動画から武器使用率を算出するためのツール群を作成した。解析結果には誤差が含まれるため、利用するためにはまだ工夫をする必要があると思う。
色々試行錯誤をする中で、モデルの性能に最も寄与したのはデータセットの作り方だった。データセットに偏りがあると、それを学習したモデルも偏りのある結果を出力する。データセットの質の重要性を、身をもって実感した。この部分については本記事で書けなかったので、またどこかで記事を書くかもしれない。
Q1 2021 Live Game Streaming Trends - Stream Hatchet ↩︎...</p>
</section>
<footer class=entry-footer><span title="2021-11-01 22:45:01 +0900 +0900">November 1, 2021</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to 機械学習を使ってApexのプレイ動画から武器使用率を算出する" href=https://kouya17.com/posts/44/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>顔認識+サーボモーターで顔追従モニターの作成
</h2>
</header>
<section class=entry-content>
<p>先日、NT金沢2021というイベントに、リモートで出展参加した。「リモートで出展参加」というのは、具体的に言うと、展示物としてはオンラインで遊べるものをポスターで出展して、私はGoogleMeet(ビデオ会議)をつないでリモートで一部作品の説明をしていた。(関係機材は現地出展した友人に運んでもらった。)
GoogleMeetをつなぐには、とりあえずPCが現地(NT金沢の会場)にあれば事足りる。ただせっかくなので、モニターが、話している相手の顔を追跡するようにした。
動作の様子 人の顔に追従するモニタを試作中…。
■使用素材
画像：いらすとや(https://t.co/H01vPNj6QI) pic.twitter.com/H8fLDuSRjz
— 青木晃也 (@aoki_kouya) May 30, 2021 検証時の動画だが、概ね完成形。当日はこのモニターに、GoogleMeetの画面を表示して運用していた。
ハードウェア 使用部品一覧 部品名 備考 JetsonNano開発者キット 顔認識・ビデオ会議・サーボ制御用 Webカメラ×2 1個は顔認識用、1個はビデオ会議用 モニター スピーカーも内蔵 サーボモーター S03T/2BBMG/F×2 強そうなものをチョイス PCA9685モジュール サーボ制御用 サーボやモニタ等を固定するための部品は3Dプリンターで作成した。
WebカメラはとりあえずAmazonで安いものを適当に買った。1種類目はUSB Wi-Fi子機との相性が良くなかったようで、Wi-Fiの接続が不安定になった。2種類目は特に問題なく動いていそうだったので、採用した。ただ、この記事を書いている時点で、採用したWebカメラのAmazonの商品ページはリンク切れになっていた。
ソフトウェア ソフトウェアに関する部分としては、JetsonNano起動後にコンソールで顔追従用プログラムを実行した後、ブラウザ(Chromium)でGoogleMeetを動かしていた。GoogleMeetの方は特に書くことがないため、顔追従用プログラムのソースコード及びセットアップ周りを書いていく。
顔追従用プログラムのソース ソースは以下に置いてある。
顔追従用プログラムのセットアップ周り 上記のソースを動かすには、関係ライブラリをインストールする必要がある。
PCA9685用ライブラリのインストール サーボ制御モジュールPCA9685をPythonから制御するためのPythonパッケージをインストールする。まず以下のコマンドでpip3をインストールする。
sudo apt-get install python3-pip 参考元: NVIDIA Jetson Nano 開発者キットに TensorFlow をインストールする - Qiita...</p>
</section>
<footer class=entry-footer><span title="2021-07-23 05:14:50 +0900 +0900">July 23, 2021</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to 顔認識+サーボモーターで顔追従モニターの作成" href=https://kouya17.com/posts/43/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>Dartでブロックチェーン(のようなもの)を実装してみた
</h2>
</header>
<section class=entry-content>
<p>以下の記事を参考にさせていただき、Dartを使ってブロックチェーン(のようなもの)を実装してみた。
動作の様子 お試しノードをHeroku上で動かしている。https://dart-blockchain-test-app.herokuapp.com/publicにアクセスすることで、 お試しノードの情報を色々見る事ができる。
ブロックチェーンは特にファイル等で永続的に残しているわけではない。Herokuはしばらくアクセスがないとアプリが停止するため、そのタイミングで情報がリセットされる。
ソースコードとローカルでのノードの立て方 ソースコードは以下に置いてある。設計部分は参考元サイトとほぼほぼ同じになっている。
ローカルPCでノードを立てる場合は、Dartの実行環境を整えた状態で、ソースコードをダウンロードし、以下のコマンドを実行すれば良い。
dart pub get dart pub global activate webdev webdev build --output web:public dart bin/back.dart --port 6565 上記コマンドを実行後、ブラウザでhttp://localhost:6565/publicにアクセスすると、ノードの情報を確認できる。
bin/back.dartを実行する際、--peerオプションで、P2P通信を行うノードを指定できる。Heroku上のお試しノードを立ち上げた状態で、以下のようにbin/back.dartを実行すれば、Heroku上のノードとの取引を行うこともできる。
dart bin/back.dart --port 6565 --peer ws://dart-blockchain-test-app.herokuapp.com/ws ローカルPC上のノードとHeroku上のノードはWebSocketでP2P通信を実現しており、簡単な構成図を書くと以下のようになる。
HerokuでDartアプリを動かす 今回Heroku上でDartアプリを実行できるようにした。Heroku上の設定周りは以下のリポジトリを利用させていただいた。
なお、上記リポジトリのREADME中にはheroku config:add BUILDPACK_URL=https://github.com/igrigorik/heroku-buildpack-dart.gitというコマンドでビルドパックを適用するよう書いてある。しかし、以下のプルリクエストにある通り、今はheroku buildpacks:set https://github.com/igrigorik/heroku-buildpack-dart.gitというコマンドでビルドパックを登録するのが正しいらしい。
とりあえず形にはなったが、まだまだ不明点がある 今回、ブロックチェーン(みたいなもの)を実装することで、ブロックチェーンへの理解が深まった。ただ、実装していく過程で、Bitcoinに対する疑問点が新たに出てきた。
マイナーへの報酬は普通のトランザクションと比べて特殊な形式になると思うが、どのような形式になっているか。 大体のネット上の記事では"悪意のあるブロックチェーンを生成するには、善意のブロックチェーンよりも長いチェーンを生成する必要があるため困難"という説明がされている。difficultyを改竄できれば、計算能力が乏しくても、いくらでも長い悪意のあるブロックチェーンを生成できそうだが、そこら辺はどのように回避しているか。 P2P通信をどのように実現しているか。 アフィリエイト
絵で見てわかるブロックチェーンの仕組み 翔泳社 (2020/12/21) Amazon Kindle 楽天ブックス 楽天Kobo </p>
</section>
<footer class=entry-footer><span title="2021-05-04 16:24:57 +0900 +0900">May 4, 2021</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to Dartでブロックチェーン(のようなもの)を実装してみた" href=https://kouya17.com/posts/42/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>Bitcoinのブロックチェーンの中身を見てみる
</h2>
</header>
<section class=entry-content>
<p>ただのにわかではあるが、ブロックチェーンは信頼性が重要な技術だと思っている。傍目から見たら、これだけ広く不特定多数に使われていても、これまで特に技術自体について大きく信頼性が揺らぐような事象は起きていないように見える。実用に十分耐えうる技術のようだ。なんとなく興味が出てきたのでゴールデンウィークの期間を使って色々勉強してみる。
Bitcoin Coreのインストール まずは暗号通貨Bitcoinを題材に、ブロックチェーンの"ブロック"の中身を見てみる。現在までのブロックを全て取得するために、以下を参考にBitcoin Coreをインストールする。
初回起動時はデータ保存場所を聞かれるが、デフォルトの場所を使うようにする。
起動後はブロックチェーンデータの同期が始まる。
完全な同期までは数日かかるらしい。自分の場合は3日ほど放置していたら完了していた。
ブロックの中身を読んでみる デフォルトだとMacOSは/Users/&lt;username>/Library/Application Support/Bitcoin/blocks/以下にブロックデータが置かれるらしい。データの総サイズを確認してみる。
$ du -hs /Users/&lt;username>/Library/Application\ Support/Bitcoin/blocks/ 361G /Users/&lt;username>/Library/Application Support/Bitcoin/blocks/ サイズがだいぶでかい。これはこれからもトランザクションが発生するごとに増えていくのだろう。
中身はバイナリになっている。フォーマットは以下のようになっているらしい。
フィールド サイズ magic bytes 4 bytes size 4 bytes block header 80 bytes tx count 可変 transaction date 可変 引用元
上記引用元サイトの情報を参考に、バイナリを読んでみる。(といっても、バイナリを読まなくても、上記引用元サイトに、必要な情報は全て書かれているので、ほぼ上記サイトの内容をかいつまんで日本語訳するような内容になる。)
$ hexdump -C -n 293 blk00000.dat 00000000 f9 be b4 d9 1d 01 00 00 01 00 00 00 00 00 00 00 |....</p>
</section>
<footer class=entry-footer><span title="2021-04-29 05:05:55 +0900 +0900">April 29, 2021</span>&nbsp;·&nbsp;3 min</footer>
<a class=entry-link aria-label="post link to Bitcoinのブロックチェーンの中身を見てみる" href=https://kouya17.com/posts/41/></a>
</article>
<article class=post-entry>
<header class=entry-header>
<h2>所定のYouTubeチャンネルの配信予定をLEDで通知する(M5StickC)
</h2>
</header>
<section class=entry-content>
<p>できたもの 動画の出来が色々とアレだが、動作時の様子を以下の動画の後半で確認できる。
動画だと映りが悪いが、写真だとLEDをつけた時の様子は以下のような感じになる。
作成目的 M5系列からYouTube Data APIを使った作例を作ってみたくて、作成した。
使用部品 M5StickC　1個 PCA9685 16チャンネル PWMモジュール　3個 フルカラーLED　12個 筐体設計 STLデータは以下に公開してある。
M5StickCとPCA9685モジュールが3個入るような箱を設計した。最初はだいぶコンパクトに設計していたのだが、配線が箱に収まらないことが分かり、途中で拡張した。もともとはM5StickCも箱の中に収める想定だったのだが、入らなかったので、横につけることにした。
フルカラーLEDは配置する場所に自由度を持たせられるように、個別に格納する箱を作成して、それぞれ4本の配線でM5StickC側の箱と接続するようにした。
配線 今回の配線の概要図を以下に示す。
PCA9685モジュールとフルカラーLEDの接続部分はテキトーになっているが、LEDについてはRGB順で1個目のLEDは1個目のPCA9685モジュールの0,1,2chに接続、2個目のLEDは1個目のPCA9685モジュールの3,4,5chに接続…という形で接続している。
ここが一番しんどかった。PCA9685モジュールを3個使っているのでやろうと思えば最大16個のフルカラーLEDを接続できるが、12個配線したところで力尽きた。
ソフト実装 ソフト全体は以下のリポジトリに置いてある。
src/main.cppについて以下の部分は各ユーザー毎に書き換える必要がある。
APIキー アクセスポイントのSSID アクセスポイントのパスワード あと、src/main.cpp中のchannelsをいじれば対象とするYouTubeチャンネルとLEDの色を変更できる。
M5StickCからYouTube Data APIを利用する部分は、以下のAPIラッパーを利用させていただいた。
ただし、このままではチャンネル情報しか取得できないため、以下の関数等を追加している。
std::vector&lt;String> YoutubeApi::getUpcomingBroadcasts(char *channelId) 指定されたChannelIDのチャンネルの配信予定(VideoID)を取得する。 BroadcastDetails YoutubeApi::getBroadcastDetails(char *videoId) 指定されたVideoIDの動画の配信詳細情報を取得する。 配信開始予定時刻は詳細情報からしか取れない。 課題 きちんと検証はしていないが、現状のソースだと、YouTube Data APIのクォータを異常に消費する。本当は1分ごとに情報取得とかをしたかったが、無料枠ではクォータが足りなくなる。
各LEDに紐づくチャンネルIDと、LEDの色がハードコーディングされているので、外部から設定できるようにしたい。
アフィリエイト
M5Stack M5StickC ESP32ミニIoT開発ボードm5stack iotキット フィンガーコンピューターカラー0....</p>
</section>
<footer class=entry-footer><span title="2021-04-03 23:09:39 +0900 +0900">April 3, 2021</span>&nbsp;·&nbsp;1 min</footer>
<a class=entry-link aria-label="post link to 所定のYouTubeチャンネルの配信予定をLEDで通知する(M5StickC)" href=https://kouya17.com/posts/40/></a>
</article>
<footer class=page-footer>
<nav class=pagination>
<a class=next href=https://kouya17.com/posts/page/2/>Next Page »</a>
</nav>
</footer>
</main>
<footer class=footer>
<p>
<span><a href=https://kouya17.com/privacy_policy/>プライバシーポリシー</a></span> |
<span><a href=https://kouya17.com/disclaimer/>免責事項</a></span> |
<span><a href="https://docs.google.com/forms/d/e/1FAIpQLSc_W9GfxBmAbLEK2id4LWDJDVTv6s4XUH86ww62e7i8e4dTjg/viewform?usp=sf_link">お問い合わせ</a></span>
</p>
<span>&copy; 2023 <a href=https://kouya17.com>kouya17.com</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>